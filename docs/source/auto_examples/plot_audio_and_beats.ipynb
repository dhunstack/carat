{
  "cells": [
    {
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "source": [
        "\n# Plot audio and beats\n\n\nThis example shows how to load/plot an audio file and the corresponding beat annotations file.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Code source: Mart\u00edn Rocamora\n# License: MIT"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "source": [
        "Imports\n  - matplotlib for visualization\n\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "from __future__ import print_function\nimport matplotlib.pyplot as plt\nimport carat"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "source": [
        "First, we'll load one of the audio files included in `carat`.\nWe get the path to the audio file example number  1, and load 10 seconds of the file.\n\n**Note 1:** By default, `carat` will resample the signal to 22050Hz, but this can disabled\nby saying `sr=None` (`carat` uses librosa for loading audio files, so it inherits\nall its functionality and behaviour).\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "audio_path = carat.util.example_audio_file(num_file=1)\n\ny, sr = carat.audio.load(audio_path, sr=None, duration=10.0)"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "source": [
        "Next, we'll load the annotations provided for the example audio file.\nWe get the path to the annotations file corresponding to example number 1,\nand then we load beats and downbeats, along with their labels.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "annotations_path = carat.util.example_beats_file(num_file=1)\n\nbeats, beat_labs = carat.annotations.load_beats(annotations_path)\ndownbeats, downbeat_labs = carat.annotations.load_downbeats(annotations_path)"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "source": [
        "**Note 2:** It is assumed that the beat annotations are provided as a text file (csv).\nApart from the time data (mandatory) a label can be given for each beat (optional).\nThe time data is assumed to be given in seconds. The labels may indicate the beat number\nwithin the rhythm cycle (e.g. 1.1, 1.2, or 1, 2).\n\n**Note 3:** The same annotations file is used for both beats and downbeats.\nThis is based on annotation labels that provide a particular string to identify the downbeats.\nIn this case, this string is .1, and is the one used by default. You can specify the string to\nlook for in the labels data to select downbeats by setting the `downbeat_label` parameter value.\nFor instance, `downbeat_label='1'` is used for loading annotations of the samba files included.\n\n**Note 4:** By default the columns are assumed to be separated by a comma, but you can specify\nanother separating string by setting the `delimiter` parameter value. For instance, a blank space\n`delimiter=' '` is used for loading annotations of the samba files included.\n\nLet's print the first 10 beat and the first 3 downbeats, with their corresponding labels.\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "print(beats[:10])\nprint(beat_labs[:10])\n\nprint(downbeats[:3])\nprint(downbeat_labs[:3])"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "source": [
        "Finally we plot the audio waveform and the beat annotations\n\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "plt.figure(figsize=(12, 6))\nax1 = plt.subplot(2, 1, 1)\ncarat.display.wave_plot(y, sr, ax=ax1)\nax2 = plt.subplot(2, 1, 2, sharex=ax1)\ncarat.display.wave_plot(y, sr, ax=ax2, beats=downbeats, beat_labs=downbeat_labs)\nplt.tight_layout()\n\nplt.show()"
      ],
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "cell_type": "code",
      "execution_count": null
    }
  ],
  "nbformat_minor": 0,
  "nbformat": 4,
  "metadata": {
    "language_info": {
      "version": "3.5.2",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}